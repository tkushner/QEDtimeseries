{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QED Supergroup: Time Series Analysis with Python\n",
    "### Taisa Kushner -- taisa.kushner(at)colorado(dot)edu\n",
    "### March 2, 2020\n",
    "\n",
    "If you'd like to follow along: \n",
    "- Go to https://nbviewer.jupyter.org/\n",
    "- Type in https://github.com/tkushner/QEDtimeseries.git \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Python & Jupyter\n",
    "\n",
    "We will be using Python3. You should already have this installed.\n",
    "\n",
    "If you'd like a nice, thorough introduction to Python, [please see this (free!) book](http://greenteapress.com/thinkpython2/thinkpython2.pdf)\n",
    "\n",
    "### Let's first take a look at the editor \"Jupyter Notebook\" that we are using today.\n",
    "\n",
    "The Jupyter Notebook:\n",
    "\n",
    "- An open source web application\n",
    "- To create and share documents that contain live code, equations, visualizations, and text\n",
    "- Ships with the IPython kernel, supports over 100 other kernels (R, Julia, etc.)\n",
    "\n",
    "Running Cells:\n",
    "\n",
    "- A Notebook’s cell defaults to using code whenever you first create one\n",
    "- Uses the kernel that you chose when you started your Notebook\n",
    "- Started with Python 3 as kernel, one can write Python code in the code cells\n",
    "- To execute a cell, you can just select the cell and click the Run button (keyboard press Shift+Enter)\n",
    "- The primary cell types are the Code and Markdown cell types\n",
    "\n",
    "Useful References:\n",
    "\n",
    "- [Jupyter Cheatsheet](https://www.edureka.co/blog/wp-content/uploads/2018/10/Jupyter_Notebook_CheatSheet_Edureka.pdf)\n",
    "- [Python Cheatsheet](https://perso.limsi.fr/pointal/_media/python:cours:mementopython3-english.pdf)\n",
    "- [Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n",
    "- [Pandas Cheatsheet](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Data management with Pandas\n",
    "\n",
    "Pandas is the open-source (under a [BSD license](https://opensource.org/licenses/BSD-2-Clause)) “Python data analysis library”, which has data structures and analysis tools geared towards analysis of numerical tables and time series. Within the world of data science, pandas is one of the most highly utilized tools due to how powerful and easy to work with the main data structure (the pandas datafame) is, especially compared to lists and dictionaries when your data comes in the form of a file (.csv, .txt, .tsv, etc). Additionally, pandas allows you to work on data sets without impacting database resources which is important if you have large data sets - more on this & related ramifications later. \n",
    "\n",
    "A note: you will find online that Pandas is designed to “fill this gap (in analysis and modeling), enabling you to carry out your entire data analysis workflow in Python”. In actuality, pandas is best suited for data analysis (preparation, cleaning, etc) rather than modeling, as the modeling capabilities are limited to linear and panel regression. Modules such as [numpy](https://numpy.org/), [scipy](https://www.scipy.org/), [statsmodels](https://www.statsmodels.org/stable/index.html) and [scikit-learn](https://scikit-learn.org/stable/), as well as software such as [Matlab](https://www.mathworks.com/solutions/mathematical-modeling.html) are better options for modeling.\n",
    "\n",
    "### Installation\n",
    "You can use either conda or pip to install pandas from the command line.\n",
    "\n",
    "`conda install pandas`\n",
    "\n",
    "Pandas depends on numpy, so when we begin our python script we need to import both numpy and pandas. It is customary to import pandas with the abbreviation “pd”:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "Pandas derives its name from “PANel DAta”. Within pandas, there are three main data structures the Series, DataFrame and Panel which build on one another with increasing levels of complexity. The best way to think about these is that the basic type is Series. A DataFrame is a container for multiple Series objects, and a Panel is a container for multiple DataFrame objects. \n",
    "\n",
    "Additionally there are experimental test bed structures Panel4D (and PanelND) which are similar to Panel except have higher dimensions. As the name implies, Panel4D has 4 named dimensions instead of 3, and PanelND is a module that allows you to construct N-dimensional named containers with custom axis labels. This is likely overkill for most of your projects, so we will not be covering these, [but you can read about them here](https://pandas.pydata.org/pandas-docs/version/0.17.0/dsintro.html#panel4d-experimental).\n",
    "\n",
    "### Data alignment (VERY IMPORTANT)\n",
    "Data alignment is intrinsic in all pandas data structures.\n",
    "\n",
    "#### What does this mean?\n",
    "##### Data is labeled & labels persist: \n",
    "When you work with pandas data objects (series, dataframes, panels) each piece of data has a label (or multiple labels) associated with it and the links between labels and data persist through all operations and will not be broken unless done so explicitly by you. This part is similar to key-value pairs in dictionaries, but you can have many keys to each value, and the keys have varying levels of importance.\n",
    "\n",
    "##### Data structures are aligned on these labels, not traditional indexes: \n",
    "The intrinsic alignment means that when you perform operations on/between multiple data frames, they get aligned and operated on by labels (called indexes), rather than a traditional location indexes. This is very useful, but can cause large problems if you do not understand how this works. We will discuss this in detail for each data type & operation, but you can think of this as follows: operations occur label-wise, not location-wise.\n",
    "\n",
    "Example:\n",
    "![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
